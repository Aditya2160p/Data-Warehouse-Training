{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark =SparkSession.builder.appName(\"june12set1\").enableHiveSupport().getOrCreate()\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "Uriat2fDXC7C",
        "outputId": "4f5ecb04-5a92-45d8-97e3-4caea3ad7f99"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f9095383dd0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - hive</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://bc029cdd0572:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>june12set1</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import Row\n",
        "data = [\n",
        "Row(OrderID=101, Customer=\"Ali\", Items=[{\"Product\":\"Laptop\", \"Qty\":1},\n",
        "{\"Product\":\"Mouse\", \"Qty\":2}], Region=\"Asia\", Amount=1200.0),\n",
        "Row(OrderID=102, Customer=\"Zara\", Items=[{\"Product\":\"Tablet\", \"Qty\":1}],\n",
        "Region=\"Europe\", Amount=650.0),\n",
        "Row(OrderID=103, Customer=\"Mohan\", Items=[{\"Product\":\"Phone\", \"Qty\":2},\n",
        "{\"Product\":\"Charger\", \"Qty\":1}], Region=\"Asia\", Amount=890.0),\n",
        "Row(OrderID=104, Customer=\"Sara\", Items=[{\"Product\":\"Desk\", \"Qty\":1}],\n",
        "Region=\"US\", Amount=450.0)\n",
        "]\n",
        "df_sales = spark.createDataFrame(data)\n",
        "df_sales.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdMmBIFlXOox",
        "outputId": "74c0efd8-97a4-4005-f953-3608f4c3b653"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+--------------------------------------------------------------+------+------+\n",
            "|OrderID|Customer|Items                                                         |Region|Amount|\n",
            "+-------+--------+--------------------------------------------------------------+------+------+\n",
            "|101    |Ali     |[{Product -> Laptop, Qty -> 1}, {Product -> Mouse, Qty -> 2}] |Asia  |1200.0|\n",
            "|102    |Zara    |[{Product -> Tablet, Qty -> 1}]                               |Europe|650.0 |\n",
            "|103    |Mohan   |[{Product -> Phone, Qty -> 2}, {Product -> Charger, Qty -> 1}]|Asia  |890.0 |\n",
            "|104    |Sara    |[{Product -> Desk, Qty -> 1}]                                 |US    |450.0 |\n",
            "+-------+--------+--------------------------------------------------------------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Working with JSON & Nested Fields\n",
        "# 1. Flatten the Items array using explode() to create one row per product.\n",
        "# 2. Count total quantity sold per product.\n",
        "# 3. Count number of orders per region.\n",
        "from pyspark.sql.functions import explode,col\n",
        "from pyspark.sql.types import IntegerType\n",
        "df_exploded=df_sales.withColumn(\"Items\",explode(\"Items\"))\n",
        "df_exploded.show()\n",
        "df_flat=df_exploded.select(\"OrderID\",\"Customer\",col(\"Items.Product\").alias(\"Product\"),col(\"Items.Qty\").cast(IntegerType()).alias(\"Qty\"),\"Region\",\"Amount\")\n",
        "df_flat.show()\n",
        "\n",
        "df_flat.groupBy(\"Product\").sum(\"Qty\").withColumnRenamed(\"sum(Qty)\", \"TotalQty\").show()\n",
        "df_flat.groupBy(\"Region\").count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fpXzI90XYWR",
        "outputId": "4faf3831-1461-48e2-be9e-3777819c156c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+--------------------+------+------+\n",
            "|OrderID|Customer|               Items|Region|Amount|\n",
            "+-------+--------+--------------------+------+------+\n",
            "|    101|     Ali|{Product -> Lapto...|  Asia|1200.0|\n",
            "|    101|     Ali|{Product -> Mouse...|  Asia|1200.0|\n",
            "|    102|    Zara|{Product -> Table...|Europe| 650.0|\n",
            "|    103|   Mohan|{Product -> Phone...|  Asia| 890.0|\n",
            "|    103|   Mohan|{Product -> Charg...|  Asia| 890.0|\n",
            "|    104|    Sara|{Product -> Desk,...|    US| 450.0|\n",
            "+-------+--------+--------------------+------+------+\n",
            "\n",
            "+-------+--------+-------+---+------+------+\n",
            "|OrderID|Customer|Product|Qty|Region|Amount|\n",
            "+-------+--------+-------+---+------+------+\n",
            "|    101|     Ali| Laptop|  1|  Asia|1200.0|\n",
            "|    101|     Ali|  Mouse|  2|  Asia|1200.0|\n",
            "|    102|    Zara| Tablet|  1|Europe| 650.0|\n",
            "|    103|   Mohan|  Phone|  2|  Asia| 890.0|\n",
            "|    103|   Mohan|Charger|  1|  Asia| 890.0|\n",
            "|    104|    Sara|   Desk|  1|    US| 450.0|\n",
            "+-------+--------+-------+---+------+------+\n",
            "\n",
            "+-------+--------+\n",
            "|Product|TotalQty|\n",
            "+-------+--------+\n",
            "| Laptop|       1|\n",
            "|  Mouse|       2|\n",
            "| Tablet|       1|\n",
            "|   Desk|       1|\n",
            "|  Phone|       2|\n",
            "|Charger|       1|\n",
            "+-------+--------+\n",
            "\n",
            "+------+-----+\n",
            "|Region|count|\n",
            "+------+-----+\n",
            "|Europe|    1|\n",
            "|  Asia|    4|\n",
            "|    US|    1|\n",
            "+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using when and otherwise\n",
        "# 4. Create a new column HighValueOrder :\n",
        "# \"Yes\" if Amount > 1000\n",
        "# \"No\" otherwise\n",
        "# 5. Add a column ShippingZone :\n",
        "# Asia → \"Zone A\", Europe → \"Zone B\", US → \"Zone C\"\n",
        "from pyspark.sql.functions import when\n",
        "df_flat=df_flat.withColumn(\"HighValueOrder\",when(col(\"Amount\")>1000,\"Yes\").otherwise(\"No\"))\n",
        "df_flat.show()\n",
        "df_flat=df_flat.withColumn(\"ShippingZone\",when(col(\"Region\")==\"Asia\",\"Zone A\").when(col(\"Region\")==\"Europe\",\"Zone B\").otherwise(\"Zone C\"))\n",
        "df_flat.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZPdH_n-Y98q",
        "outputId": "5da05e2a-93ba-43ea-a611-297a8382d3bd"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+-------+---+------+------+--------------+\n",
            "|OrderID|Customer|Product|Qty|Region|Amount|HighValueOrder|\n",
            "+-------+--------+-------+---+------+------+--------------+\n",
            "|    101|     Ali| Laptop|  1|  Asia|1200.0|           Yes|\n",
            "|    101|     Ali|  Mouse|  2|  Asia|1200.0|           Yes|\n",
            "|    102|    Zara| Tablet|  1|Europe| 650.0|            No|\n",
            "|    103|   Mohan|  Phone|  2|  Asia| 890.0|            No|\n",
            "|    103|   Mohan|Charger|  1|  Asia| 890.0|            No|\n",
            "|    104|    Sara|   Desk|  1|    US| 450.0|            No|\n",
            "+-------+--------+-------+---+------+------+--------------+\n",
            "\n",
            "+-------+--------+-------+---+------+------+--------------+------------+\n",
            "|OrderID|Customer|Product|Qty|Region|Amount|HighValueOrder|ShippingZone|\n",
            "+-------+--------+-------+---+------+------+--------------+------------+\n",
            "|    101|     Ali| Laptop|  1|  Asia|1200.0|           Yes|      Zone A|\n",
            "|    101|     Ali|  Mouse|  2|  Asia|1200.0|           Yes|      Zone A|\n",
            "|    102|    Zara| Tablet|  1|Europe| 650.0|            No|      Zone B|\n",
            "|    103|   Mohan|  Phone|  2|  Asia| 890.0|            No|      Zone A|\n",
            "|    103|   Mohan|Charger|  1|  Asia| 890.0|            No|      Zone A|\n",
            "|    104|    Sara|   Desk|  1|    US| 450.0|            No|      Zone C|\n",
            "+-------+--------+-------+---+------+------+--------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Temporary & Permanent Views\n",
        "# 6. Register df_sales as a temporary view named sales_view .\n",
        "# 7. Write a SQL query to:\n",
        "# Count orders by Region\n",
        "# Find average amount per region\n",
        "# 8. Create a permanent view using saveAsTable() .\n",
        "sales_view=df_sales.createOrReplaceTempView(\"sales_view\")\n",
        "spark.sql(\"select Region,count(*) as regioncount from sales_view group by Region\").show()\n",
        "spark.sql(\"select Region,avg(Amount) from sales_view group by Region\").show()\n",
        "df_sales.write.mode(\"overwrite\").saveAsTable(\"sales_table\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bi4KdFP6bLdJ",
        "outputId": "4f3c33b2-f6b0-47e4-82d1-ea3f9e5c4eda"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------+\n",
            "|Region|regioncount|\n",
            "+------+-----------+\n",
            "|Europe|          1|\n",
            "|  Asia|          2|\n",
            "|    US|          1|\n",
            "+------+-----------+\n",
            "\n",
            "+------+-----------+\n",
            "|Region|avg(Amount)|\n",
            "+------+-----------+\n",
            "|Europe|      650.0|\n",
            "|  Asia|     1045.0|\n",
            "|    US|      450.0|\n",
            "+------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SQL Queries via Spark\n",
        "# 9. Use SQL to filter all orders with more than 1 item.\n",
        "# 10. Use SQL to extract customer names where Amount > 800.\n",
        "spark.sql(\"SELECT OrderID, Customer, Size(Items) as ItemCount FROM sales_view WHERE Size(Items) > 1\").show()\n",
        "spark.sql(\"SELECT Customer FROM sales_view WHERE Amount > 800\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcjWRoB4cbbq",
        "outputId": "ffe7c5f3-f34d-4a21-f08d-971cdb67e7df"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+---------+\n",
            "|OrderID|Customer|ItemCount|\n",
            "+-------+--------+---------+\n",
            "|    101|     Ali|        2|\n",
            "|    103|   Mohan|        2|\n",
            "+-------+--------+---------+\n",
            "\n",
            "+--------+\n",
            "|Customer|\n",
            "+--------+\n",
            "|     Ali|\n",
            "|   Mohan|\n",
            "+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving as Parquet and Reading Again\n",
        "# 11. Save the exploded product-level DataFrame as a partitioned Parquet file byRegion .\n",
        "# 12. Read the parquet back and perform a group-by on Product .\n",
        "\n",
        "\n",
        "df_parquet = spark.read.parquet(\"/content/drive/MyDrive/ParquetData/sales_by_region\")\n",
        "df_parquet.show()\n",
        "df_parquet.groupBy(\"Product\").count().show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7p1ZLrcScwfx",
        "outputId": "ccfde8fe-b383-49c8-cc1b-81d95f45daee"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+-------+---+------+------+\n",
            "|OrderID|Customer|Product|Qty|Amount|Region|\n",
            "+-------+--------+-------+---+------+------+\n",
            "|    103|   Mohan|  Phone|  2| 890.0|  Asia|\n",
            "|    103|   Mohan|Charger|  1| 890.0|  Asia|\n",
            "|    101|     Ali| Laptop|  1|1200.0|  Asia|\n",
            "|    101|     Ali|  Mouse|  2|1200.0|  Asia|\n",
            "|    102|    Zara| Tablet|  1| 650.0|Europe|\n",
            "|    104|    Sara|   Desk|  1| 450.0|    US|\n",
            "+-------+--------+-------+---+------+------+\n",
            "\n",
            "+-------+-----+\n",
            "|Product|count|\n",
            "+-------+-----+\n",
            "|  Phone|    1|\n",
            "| Laptop|    1|\n",
            "|Charger|    1|\n",
            "|  Mouse|    1|\n",
            "|   Desk|    1|\n",
            "| Tablet|    1|\n",
            "+-------+-----+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}