{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d76eead-a817-48fc-b245-6aff79bda87b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LogID: string (nullable = true)\n",
      " |-- VehicleID: string (nullable = true)\n",
      " |-- EntryPoint: string (nullable = true)\n",
      " |-- ExitPoint: string (nullable = true)\n",
      " |-- EntryTime: timestamp (nullable = true)\n",
      " |-- ExitTime: timestamp (nullable = true)\n",
      " |-- VehicleType: string (nullable = true)\n",
      " |-- SpeedKMH: integer (nullable = true)\n",
      " |-- TollPaid: integer (nullable = true)\n",
      "\n",
      "+-----+---------+----------+---------+-------------------+-------------------+-----------+--------+--------+\n",
      "|LogID|VehicleID|EntryPoint|ExitPoint|          EntryTime|           ExitTime|VehicleType|SpeedKMH|TollPaid|\n",
      "+-----+---------+----------+---------+-------------------+-------------------+-----------+--------+--------+\n",
      "| L001|     V001|     GateA|    GateC|2024-05-01 08:01:00|2024-05-01 08:20:00|        Car|      60|      50|\n",
      "| L002|     V002|     GateB|    GateC|2024-05-01 08:10:00|2024-05-01 08:45:00|      Truck|      45|     100|\n",
      "| L003|     V003|     GateA|    GateD|2024-05-01 09:00:00|2024-05-01 09:18:00|       Bike|      55|      30|\n",
      "| L004|     V004|     GateC|    GateD|2024-05-01 09:15:00|2024-05-01 09:35:00|        Car|      80|      50|\n",
      "| L005|     V005|     GateB|    GateA|2024-05-01 10:05:00|2024-05-01 10:40:00|        Bus|      40|      70|\n",
      "+-----+---------+----------+---------+-------------------+-------------------+-----------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "# Data Ingestion & Schema Analysis\n",
    "# Load CSV using PySpark with schema inference\n",
    "# Manually define schema and compare\n",
    "# Ensure EntryTime/ExitTime are timestamp\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "df = spark.read.csv(\"file:/Workspace/Shared/traffic_logs19.csv\",header=True,inferSchema=True)\n",
    "df.printSchema()\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"LogID\", StringType(), True),\n",
    "    StructField(\"VehicleID\", StringType(), True),\n",
    "    StructField(\"EntryPoint\", StringType(), True),\n",
    "    StructField(\"ExitPoint\", StringType(), True),\n",
    "    StructField(\"EntryTime\", TimestampType(), True),\n",
    "    StructField(\"ExitTime\", TimestampType(), True),\n",
    "    StructField(\"VehicleType\", StringType(), True),\n",
    "    StructField(\"SpeedKMH\", DoubleType(), True),\n",
    "    StructField(\"TollPaid\", DoubleType(), True),\n",
    "])\n",
    "tl= spark.read.csv(\"file:/Workspace/Shared/traffic_logs19.csv\",header=True,inferSchema=True)\n",
    "tl.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2c0e03f-7f74-4b05-a8d7-a0badec5ba86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+----------+---------+-------------------+-------------------+-----------+--------+--------+-------------------+-----------+\n",
      "|LogID|VehicleID|EntryPoint|ExitPoint|          EntryTime|           ExitTime|VehicleType|SpeedKMH|TollPaid|TripDurationMinutes|IsOverspeed|\n",
      "+-----+---------+----------+---------+-------------------+-------------------+-----------+--------+--------+-------------------+-----------+\n",
      "| L001|     V001|     GateA|    GateC|2024-05-01 08:01:00|2024-05-01 08:20:00|        Car|      60|      50|               19.0|      false|\n",
      "| L002|     V002|     GateB|    GateC|2024-05-01 08:10:00|2024-05-01 08:45:00|      Truck|      45|     100|               35.0|      false|\n",
      "| L003|     V003|     GateA|    GateD|2024-05-01 09:00:00|2024-05-01 09:18:00|       Bike|      55|      30|               18.0|      false|\n",
      "| L004|     V004|     GateC|    GateD|2024-05-01 09:15:00|2024-05-01 09:35:00|        Car|      80|      50|               20.0|       true|\n",
      "| L005|     V005|     GateB|    GateA|2024-05-01 10:05:00|2024-05-01 10:40:00|        Bus|      40|      70|               35.0|      false|\n",
      "+-----+---------+----------+---------+-------------------+-------------------+-----------+--------+--------+-------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2\n",
    "# Derived Column Creation\n",
    "# Calculate TripDurationMinutes = ExitTime - EntryTime\n",
    "# Add IsOverspeed = SpeedKMH > 60\n",
    "df = df.withColumn(\"TripDurationMinutes\",round((col(\"ExitTime\").cast(\"long\") - col(\"EntryTime\").cast(\"long\")) / 60.0, 2)).withColumn(\"IsOverspeed\", col(\"SpeedKMH\") > 60)\n",
    "df.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3234f562-a60c-481f-b70b-82d2cbf9040b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+\n",
      "|VehicleType|avg(SpeedKMH)|\n",
      "+-----------+-------------+\n",
      "|       Bike|         55.0|\n",
      "|        Car|         70.0|\n",
      "|      Truck|         45.0|\n",
      "|        Bus|         40.0|\n",
      "+-----------+-------------+\n",
      "\n",
      "+----------+-------------+\n",
      "|EntryPoint|sum(TollPaid)|\n",
      "+----------+-------------+\n",
      "|     GateA|           80|\n",
      "|     GateB|          170|\n",
      "|     GateC|           50|\n",
      "+----------+-------------+\n",
      "\n",
      "+---------+---+\n",
      "|ExitPoint|cnt|\n",
      "+---------+---+\n",
      "|    GateD|  2|\n",
      "+---------+---+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3\n",
    "# Vehicle Behavior Aggregations\n",
    "# Average speed per VehicleType\n",
    "# Total toll collected per gate (EntryPoint)\n",
    "# Most used ExitPoint\n",
    "\n",
    "df.groupBy(\"VehicleType\").avg(\"SpeedKMH\").show()\n",
    "\n",
    "\n",
    "df.groupBy(\"EntryPoint\").sum(\"TollPaid\").show()\n",
    "\n",
    "\n",
    "df.groupBy(\"ExitPoint\").agg(count(\"*\").alias(\"cnt\")).orderBy(col(\"cnt\").desc()).show(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2af4f658-8c6b-4221-9a8b-6cd10ad80df1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+----------+---------+-------------------+-------------------+-----------+--------+--------+-------------------+-----------+---------+--------+\n",
      "|LogID|VehicleID|EntryPoint|ExitPoint|          EntryTime|           ExitTime|VehicleType|SpeedKMH|TollPaid|TripDurationMinutes|IsOverspeed|SpeedRank|LastExit|\n",
      "+-----+---------+----------+---------+-------------------+-------------------+-----------+--------+--------+-------------------+-----------+---------+--------+\n",
      "| L001|     V001|     GateA|    GateC|2024-05-01 08:01:00|2024-05-01 08:20:00|        Car|      60|      50|               19.0|      false|        2|    NULL|\n",
      "| L002|     V002|     GateB|    GateC|2024-05-01 08:10:00|2024-05-01 08:45:00|      Truck|      45|     100|               35.0|      false|        1|    NULL|\n",
      "| L003|     V003|     GateA|    GateD|2024-05-01 09:00:00|2024-05-01 09:18:00|       Bike|      55|      30|               18.0|      false|        1|    NULL|\n",
      "| L004|     V004|     GateC|    GateD|2024-05-01 09:15:00|2024-05-01 09:35:00|        Car|      80|      50|               20.0|       true|        1|    NULL|\n",
      "| L005|     V005|     GateB|    GateA|2024-05-01 10:05:00|2024-05-01 10:40:00|        Bus|      40|      70|               35.0|      false|        1|    NULL|\n",
      "+-----+---------+----------+---------+-------------------+-------------------+-----------+--------+--------+-------------------+-----------+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 4\n",
    "# Window Functions\n",
    "# Rank vehicles by speed within VehicleType\n",
    "# Find last exit time for each vehicle using lag()\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "win = Window.partitionBy(\"VehicleType\").orderBy(col(\"SpeedKMH\").desc())\n",
    "df3 = df.withColumn(\"SpeedRank\", rank().over(win))\n",
    "\n",
    "win2 = Window.partitionBy(\"VehicleID\").orderBy(\"ExitTime\")\n",
    "df3 = df3.withColumn(\"LastExit\", lag(\"ExitTime\").over(win2))\n",
    "df3.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59976dc5-33ab-490f-bc4b-94b979e10ace",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+----------+---------+-------------------+-------------------+-----------+--------+--------+-------------------+-----------+---------+--------+-----------+\n",
      "|LogID|VehicleID|EntryPoint|ExitPoint|          EntryTime|           ExitTime|VehicleType|SpeedKMH|TollPaid|TripDurationMinutes|IsOverspeed|SpeedRank|LastExit|IdleMinutes|\n",
      "+-----+---------+----------+---------+-------------------+-------------------+-----------+--------+--------+-------------------+-----------+---------+--------+-----------+\n",
      "| L001|     V001|     GateA|    GateC|2024-05-01 08:01:00|2024-05-01 08:20:00|        Car|      60|      50|               19.0|      false|        2|    NULL|       NULL|\n",
      "| L002|     V002|     GateB|    GateC|2024-05-01 08:10:00|2024-05-01 08:45:00|      Truck|      45|     100|               35.0|      false|        1|    NULL|       NULL|\n",
      "| L003|     V003|     GateA|    GateD|2024-05-01 09:00:00|2024-05-01 09:18:00|       Bike|      55|      30|               18.0|      false|        1|    NULL|       NULL|\n",
      "| L004|     V004|     GateC|    GateD|2024-05-01 09:15:00|2024-05-01 09:35:00|        Car|      80|      50|               20.0|       true|        1|    NULL|       NULL|\n",
      "| L005|     V005|     GateB|    GateA|2024-05-01 10:05:00|2024-05-01 10:40:00|        Bus|      40|      70|               35.0|      false|        1|    NULL|       NULL|\n",
      "+-----+---------+----------+---------+-------------------+-------------------+-----------+--------+--------+-------------------+-----------+---------+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5\n",
    "# Session Segmentation\n",
    "# Group by VehicleID to simulate route sessions\n",
    "# Find duration between subsequent trips (idle time)\n",
    "df3 = df3.withColumn(\"IdleMinutes\",(unix_timestamp(\"EntryTime\") - unix_timestamp(\"LastExit\"))/60)\n",
    "df3.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "753083f5-20ca-47b3-a5fc-34d5bfa2fdbf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+----------+---------+-------------------+-------------------+-----------+--------+--------+-------------------+-----------+---------+--------+-----------+\n",
      "|LogID|VehicleID|EntryPoint|ExitPoint|          EntryTime|           ExitTime|VehicleType|SpeedKMH|TollPaid|TripDurationMinutes|IsOverspeed|SpeedRank|LastExit|IdleMinutes|\n",
      "+-----+---------+----------+---------+-------------------+-------------------+-----------+--------+--------+-------------------+-----------+---------+--------+-----------+\n",
      "| L005|     V005|     GateB|    GateA|2024-05-01 10:05:00|2024-05-01 10:40:00|        Bus|      40|      70|               35.0|      false|        1|    NULL|       NULL|\n",
      "+-----+---------+----------+---------+-------------------+-------------------+-----------+--------+--------+-------------------+-----------+---------+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 6\n",
    "# Anomaly Detection\n",
    "# Identify vehicles with speed > 70 and TripDuration < 10 minutes\n",
    "# Vehicles that paid less toll for longer trips\n",
    "# Suspicious backtracking (ExitPoint earlier than EntryPoint)\n",
    "anomalies = df3.filter((col(\"SpeedKMH\") > 70) & (col(\"TripDurationMinutes\") < 10)|(col(\"TollPaid\") < 5) & (col(\"TripDurationMinutes\") > 30) |(col(\"ExitPoint\") < col(\"EntryPoint\")))\n",
    "anomalies.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92d37d1d-9d71-4fc8-9b5f-fa51a3884fb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|RegisteredCity|count|\n",
      "+--------------+-----+\n",
      "|     Bangalore|    1|\n",
      "|       Chennai|    1|\n",
      "|        Mumbai|    1|\n",
      "|          Pune|    1|\n",
      "|         Delhi|    1|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 7\n",
    "# Join with Metadata\n",
    "# Prepare this small vehicle_registry.csv :\n",
    "# VehicleID,OwnerName,Model,RegisteredCity\n",
    "# V001,Anil,Hyundai i20,Delhi\n",
    "# V002,Rakesh,Tata Truck,Chennai\n",
    "# V003,Sana,Yamaha R15,Mumbai\n",
    "# V004,Neha,Honda City,Bangalore\n",
    "# V005,Zoya,Volvo Bus,Pune\n",
    "# Join and group trips by RegisteredCity\n",
    "veh = spark.read.csv(\"file:/Workspace/Shared/vehicle_registry19.csv\",header=True,inferSchema=True)\n",
    "\n",
    "df4 = df3.join(veh, \"VehicleID\", \"left\")\n",
    "df4.groupBy(\"RegisteredCity\").count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c42e3c0f-7ed9-4da4-ac67-9a9a8ea20a63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+----------+---------+-------------------+-------------------+-----------+--------+--------+-------------------+-----------+---------+--------+-----------+---------+-----------+--------------+\n",
      "|VehicleID|LogID|EntryPoint|ExitPoint|          EntryTime|           ExitTime|VehicleType|SpeedKMH|TollPaid|TripDurationMinutes|IsOverspeed|SpeedRank|LastExit|IdleMinutes|OwnerName|      Model|RegisteredCity|\n",
      "+---------+-----+----------+---------+-------------------+-------------------+-----------+--------+--------+-------------------+-----------+---------+--------+-----------+---------+-----------+--------------+\n",
      "|     V001| L001|     GateA|    GateC|2024-05-01 08:01:00|2024-05-01 08:20:00|        Car|      60|      50|               19.0|      false|        2|    NULL|       NULL|     Anil|Hyundai i20|         Delhi|\n",
      "|     V002| L002|     GateB|    GateC|2024-05-01 08:10:00|2024-05-01 08:45:00|      Truck|      45|     100|               35.0|      false|        1|    NULL|       NULL|   Rakesh| Tata Truck|       Chennai|\n",
      "|     V003| L003|     GateA|    GateD|2024-05-01 09:00:00|2024-05-01 09:18:00|       Bike|      55|      30|               18.0|      false|        1|    NULL|       NULL|     Sana| Yamaha R15|        Mumbai|\n",
      "|     V004| L004|     GateC|    GateD|2024-05-01 09:15:00|2024-05-01 09:35:00|        Car|      80|      50|               20.0|       true|        1|    NULL|       NULL|     Neha| Honda City|     Bangalore|\n",
      "|     V005| L005|     GateB|    GateA|2024-05-01 10:05:00|2024-05-01 10:40:00|        Bus|      40|      70|               35.0|      false|        1|    NULL|       NULL|     Zoya|  Volvo Bus|          Pune|\n",
      "+---------+-----+----------+---------+-------------------+-------------------+-----------+--------+--------+-------------------+-----------+---------+--------+-----------+---------+-----------+--------------+\n",
      "\n",
      "+-------+-------------------+----------------+--------------------+---------+--------------------+----+------------------+--------------------+-----------+-----------------+-------------+--------------------+------------+--------------------+\n",
      "|version|          timestamp|          userId|            userName|operation| operationParameters| job|          notebook|           clusterId|readVersion|   isolationLevel|isBlindAppend|    operationMetrics|userMetadata|          engineInfo|\n",
      "+-------+-------------------+----------------+--------------------+---------+--------------------+----+------------------+--------------------+-----------+-----------------+-------------+--------------------+------------+--------------------+\n",
      "|     17|2025-06-19 04:53:54|1679761755594499|azuser3546_mml.lo...| OPTIMIZE|{predicate -> [],...|NULL|{2977741827703189}|0612-091342-i15khidz|         15|SnapshotIsolation|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
      "|     16|2025-06-19 04:53:53|1679761755594499|azuser3546_mml.lo...|   DELETE|{predicate -> [\"(...|NULL|{2977741827703189}|0612-091342-i15khidz|         15|WriteSerializable|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
      "|     15|2025-06-19 04:53:52|1679761755594499|azuser3546_mml.lo...|   UPDATE|{predicate -> [\"(...|NULL|{2977741827703189}|0612-091342-i15khidz|         14|WriteSerializable|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
      "|     14|2025-06-19 04:42:36|1679761755594499|azuser3546_mml.lo...| OPTIMIZE|{predicate -> [],...|NULL|{2977741827703189}|0612-091342-i15khidz|         12|SnapshotIsolation|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
      "|     13|2025-06-19 04:42:35|1679761755594499|azuser3546_mml.lo...|   DELETE|{predicate -> [\"(...|NULL|{2977741827703189}|0612-091342-i15khidz|         12|WriteSerializable|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
      "|     12|2025-06-19 04:42:33|1679761755594499|azuser3546_mml.lo...|   UPDATE|{predicate -> [\"(...|NULL|{2977741827703189}|0612-091342-i15khidz|         11|WriteSerializable|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
      "|     11|2025-06-19 04:38:31|1679761755594499|azuser3546_mml.lo...| OPTIMIZE|{predicate -> [],...|NULL|{2977741827703189}|0612-091342-i15khidz|         10|SnapshotIsolation|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
      "|     10|2025-06-19 04:38:28|1679761755594499|azuser3546_mml.lo...|   DELETE|{predicate -> [\"(...|NULL|{2977741827703189}|0612-091342-i15khidz|          9|WriteSerializable|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
      "|      9|2025-06-19 04:38:27|1679761755594499|azuser3546_mml.lo...|   UPDATE|{predicate -> [\"(...|NULL|{2977741827703189}|0612-091342-i15khidz|          8|WriteSerializable|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
      "|      8|2025-06-19 04:38:24|1679761755594499|azuser3546_mml.lo...|    WRITE|{mode -> Overwrit...|NULL|{2977741827703189}|0612-091342-i15khidz|          7|WriteSerializable|        false|{numFiles -> 1, n...|        NULL|Databricks-Runtim...|\n",
      "|      7|2025-06-19 04:38:04|1679761755594499|azuser3546_mml.lo...| OPTIMIZE|{predicate -> [],...|NULL|{2977741827703189}|0612-091342-i15khidz|          6|SnapshotIsolation|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
      "|      6|2025-06-19 04:38:02|1679761755594499|azuser3546_mml.lo...|   DELETE|{predicate -> [\"(...|NULL|{2977741827703189}|0612-091342-i15khidz|          5|WriteSerializable|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
      "|      5|2025-06-19 04:38:00|1679761755594499|azuser3546_mml.lo...|   UPDATE|{predicate -> [\"(...|NULL|{2977741827703189}|0612-091342-i15khidz|          4|WriteSerializable|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
      "|      4|2025-06-19 04:37:57|1679761755594499|azuser3546_mml.lo...|    WRITE|{mode -> Overwrit...|NULL|{2977741827703189}|0612-091342-i15khidz|          3|WriteSerializable|        false|{numFiles -> 1, n...|        NULL|Databricks-Runtim...|\n",
      "|      3|2025-06-19 04:37:09|1679761755594499|azuser3546_mml.lo...| OPTIMIZE|{predicate -> [],...|NULL|{2977741827703189}|0612-091342-i15khidz|          2|SnapshotIsolation|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
      "|      2|2025-06-19 04:37:06|1679761755594499|azuser3546_mml.lo...|   DELETE|{predicate -> [\"(...|NULL|{2977741827703189}|0612-091342-i15khidz|          1|WriteSerializable|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
      "|      1|2025-06-19 04:37:04|1679761755594499|azuser3546_mml.lo...|   UPDATE|{predicate -> [\"(...|NULL|{2977741827703189}|0612-091342-i15khidz|          0|WriteSerializable|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
      "|      0|2025-06-19 04:36:55|1679761755594499|azuser3546_mml.lo...|    WRITE|{mode -> Overwrit...|NULL|{2977741827703189}|0612-091342-i15khidz|       NULL|WriteSerializable|        false|{numFiles -> 1, n...|        NULL|Databricks-Runtim...|\n",
      "+-------+-------------------+----------------+--------------------+---------+--------------------+----+------------------+--------------------+-----------+-----------------+-------------+--------------------+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 8\n",
    "# Delta Lake Features\n",
    "# Save traffic_logs as Delta Table\n",
    "# Apply MERGE INTO to update toll rates for all Bikes\n",
    "# Delete trips longer than 60 minutes\n",
    "# Use DESCRIBE HISTORY and VERSION AS OF\n",
    "df4.write.format(\"delta\").mode(\"overwrite\").save(\"file:/Workspace/Shared/traffic_logs\")\n",
    "spark.read.format(\"delta\").load(\"file:/Workspace/Shared/traffic_logs\").createOrReplaceTempView(\"traffic_delta\")\n",
    "\n",
    "from delta.tables import DeltaTable\n",
    "dl = DeltaTable.forPath(spark, \"file:/Workspace/Shared/traffic_logs\")\n",
    "dl.update(condition=col(\"VehicleType\")==\"Bike\", set={\"TollPaid\": col(\"TollPaid\")*1.1})\n",
    "\n",
    "dl.delete(condition=col(\"TripDurationMinutes\") > 60)\n",
    "\n",
    "spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(\"file:/Workspace/Shared/traffic_logs\").show()\n",
    "spark.sql(\"DESCRIBE HISTORY delta.`file:/Workspace/Shared/traffic_logs`\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2e0347c-4211-4b65-9f38-dd2e7993fa57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 9\n",
    "# Advanced Conditions\n",
    "# when/otherwise : Tag trip type as:\n",
    "# \"Short\" <15min\n",
    "# \"Medium\" 15-30min\n",
    "# \"Long\" >30min\n",
    "\n",
    "df3 = df.withColumn(\n",
    "    \"TripType\",\n",
    "    when(col(\"TripDurationMinutes\") < 15, \"Short\")\n",
    "    .when((col(\"TripDurationMinutes\") >= 15) & (col(\"TripDurationMinutes\") <= 30), \"Medium\")\n",
    "    .otherwise(\"Long\")\n",
    ")\n",
    "\n",
    "\n",
    "df3 = df3.withColumn(\"TripDate\", to_date(\"EntryTime\"))\n",
    "\n",
    "trip_counts = df3.groupBy(\"VehicleID\", \"TripDate\").agg(count(\"*\").alias(\"TripCount\"))\n",
    "\n",
    "df4 = df3.join(trip_counts, [\"VehicleID\", \"TripDate\"]).withColumn(\n",
    "    \"FlaggedFrequent\", when(col(\"TripCount\") > 3, True).otherwise(False)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe3481ca-7681-41db-85ce-aa944491df76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+---------+\n",
      "|VehicleType|ExitPoint|TotalToll|\n",
      "+-----------+---------+---------+\n",
      "|      Truck|    GateC|      100|\n",
      "|        Bus|    GateA|       70|\n",
      "|        Car|    GateC|       50|\n",
      "|        Car|    GateD|       50|\n",
      "|       Bike|    GateD|       30|\n",
      "+-----------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Export & Reporting\n",
    "# Write final enriched DataFrame to:\n",
    "# Parquet partitioned by VehicleType\n",
    "# CSV for dashboards\n",
    "# Create summary SQL View: total toll by VehicleType + ExitPoint\n",
    "df4.write.mode(\"overwrite\").partitionBy(\"VehicleType\").parquet(\"file:/Workspace/Shared/traffic_data_parquet\")\n",
    "df4.write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"file:/Workspace/Shared/traffic_data_csv\")\n",
    "df4.createOrReplaceTempView(\"traffic_logs_view\")\n",
    "\n",
    "summary_df = spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT VehicleType, ExitPoint, SUM(TollPaid) AS TotalToll\n",
    "    FROM traffic_logs_view\n",
    "    GROUP BY VehicleType, ExitPoint\n",
    "    ORDER BY TotalToll DESC\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "summary_df.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "june19set1",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
