{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "AvbVOkdgT9AR",
        "outputId": "68af5fcc-7966-4875-a306-0f3e8f2e7244"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7daf359097d0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - hive</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://3141bbf6aa85:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>PySparkAssessment2</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark =SparkSession.builder.appName(\"PySparkAssessment2\").enableHiveSupport().getOrCreate()\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "file_path = '/content/drive/MyDrive/PysparkDemo/large_employee_dataset.csv'\n",
        "print(os.path.exists(file_path))"
      ],
      "metadata": {
        "id": "0U9-9XTjUA8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Ingestion & Exploration\n",
        "# Read all 3 files (CSV + JSON) using PySpark.\n",
        "# Show schemas and sample records.\n",
        "# Count distinct departments.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "\n",
        "\n",
        "employeesdf =spark.read.csv('/content/drive/MyDrive/PysparkDemo/employees.csv',header=True,inferSchema=True)\n",
        "attendancedf = spark.read.csv('/content/drive/MyDrive/PysparkDemo/attendance.csv',header=True,inferSchema=True)\n",
        "bonusesdf = spark.read.option(\"multiline\", True).json('/content/drive/MyDrive/PysparkDemo/bonuses.json')\n",
        "\n",
        "employeesdf.printSchema()\n",
        "employeesdf.show()\n",
        "\n",
        "attendancedf.printSchema()\n",
        "attendancedf.show()\n",
        "\n",
        "bonusesdf.printSchema()\n",
        "bonusesdf.show()\n",
        "\n",
        "employeesdf.select(\"Department\").distinct().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoFyfW-5UEbQ",
        "outputId": "55e0e859-105f-4567-bb2a-29287c200c88"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "root\n",
            " |-- EmpID: integer (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Department: string (nullable = true)\n",
            " |-- JoinDate: date (nullable = true)\n",
            " |-- Salary: integer (nullable = true)\n",
            " |-- ManagerID: integer (nullable = true)\n",
            "\n",
            "+-----+------+-----------+----------+------+---------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|\n",
            "+-----+------+-----------+----------+------+---------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|     NULL|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|\n",
            "+-----+------+-----------+----------+------+---------+\n",
            "\n",
            "root\n",
            " |-- EmpID: integer (nullable = true)\n",
            " |-- Date: date (nullable = true)\n",
            " |-- Status: string (nullable = true)\n",
            "\n",
            "+-----+----------+-------+\n",
            "|EmpID|      Date| Status|\n",
            "+-----+----------+-------+\n",
            "|    1|2024-04-01|Present|\n",
            "|    1|2024-04-02|Present|\n",
            "|    2|2024-04-01| Absent|\n",
            "|    2|2024-04-02|Present|\n",
            "|    3|2024-04-01|Present|\n",
            "|    3|2024-04-02|Present|\n",
            "|    4|2024-04-01| Absent|\n",
            "|    4|2024-04-02| Absent|\n",
            "|    5|2024-04-01|Present|\n",
            "|    5|2024-04-02|Present|\n",
            "+-----+----------+-------+\n",
            "\n",
            "root\n",
            " |-- Bonus: long (nullable = true)\n",
            " |-- EmpID: long (nullable = true)\n",
            " |-- Year: long (nullable = true)\n",
            "\n",
            "+-----+-----+----+\n",
            "|Bonus|EmpID|Year|\n",
            "+-----+-----+----+\n",
            "| 5000|    1|2023|\n",
            "| 7000|    2|2023|\n",
            "| 6500|    3|2023|\n",
            "| 6000|    4|2023|\n",
            "| 4000|    5|2023|\n",
            "+-----+-----+----+\n",
            "\n",
            "+-----------+\n",
            "| Department|\n",
            "+-----------+\n",
            "|Engineering|\n",
            "|         HR|\n",
            "|  Marketing|\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. DataFrame Operations\n",
        "# Add a column TenureYears using datediff() and round() .\n",
        "# Calculate TotalCompensation = Salary + Bonus .\n",
        "# Filter employees with more than 2 years in the company.\n",
        "# Show employees who report to a manager ( ManagerID is not null ).\n",
        "\n",
        "from pyspark.sql.functions import to_date,datediff,col,round,current_date\n",
        "\n",
        "employeesdf = employeesdf.withColumn(\"JoinDate\", to_date(\"JoinDate\"))\n",
        "employeesdf = employeesdf.withColumn(\"TenureYears\", round(datediff(current_date(), col(\"JoinDate\")) / 365, 2))\n",
        "\n",
        "emp_with_bonus = employeesdf.join(bonusesdf, \"EmpID\")\n",
        "emp_with_bonus = emp_with_bonus.withColumn(\"TotalCompensation\", col(\"Salary\") + col(\"Bonus\"))\n",
        "\n",
        "\n",
        "emp_with_bonus.filter(col(\"TenureYears\") > 2).show()\n",
        "\n",
        "\n",
        "employeesdf.filter(col(\"ManagerID\").isNotNull()).show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5ef3kaVVwlZ",
        "outputId": "40222431-176b-4fe9-9cc0-c7149f0d236a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|Bonus|Year|TotalCompensation|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|     NULL|       4.11| 5000|2023|            60000|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|       5.24| 7000|2023|            87000|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|       2.92| 6500|2023|            81500|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|       5.56| 6000|2023|            66000|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|       2.43| 4000|2023|            54000|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+\n",
            "\n",
            "+-----+------+-----------+----------+------+---------+-----------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|\n",
            "+-----+------+-----------+----------+------+---------+-----------+\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|       5.24|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|       2.92|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|       5.56|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|       2.43|\n",
            "+-----+------+-----------+----------+------+---------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Aggregation\n",
        "# Average salary per department.\n",
        "# Number of employees under each manager.\n",
        "# Count of absences per employee.\n",
        "\n",
        "employeesdf.groupBy(\"Department\").agg({\"Salary\": \"avg\"}).show()\n",
        "employeesdf.groupBy(\"ManagerID\").agg({\"EmpID\": \"count\"}).show()\n",
        "attendancedf.filter(col(\"Status\") == \"Absent\").groupBy(\"EmpID\").count().withColumnRenamed(\"count\", \"AbsenceCount\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiFdj4slVwdw",
        "outputId": "3ed05660-c7fb-4697-ab6d-271341bbb1b6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+\n",
            "| Department|avg(Salary)|\n",
            "+-----------+-----------+\n",
            "|Engineering|    77500.0|\n",
            "|         HR|    52500.0|\n",
            "|  Marketing|    60000.0|\n",
            "+-----------+-----------+\n",
            "\n",
            "+---------+------------+\n",
            "|ManagerID|count(EmpID)|\n",
            "+---------+------------+\n",
            "|     NULL|           1|\n",
            "|        1|           4|\n",
            "+---------+------------+\n",
            "\n",
            "+-----+------------+\n",
            "|EmpID|AbsenceCount|\n",
            "+-----+------------+\n",
            "|    4|           2|\n",
            "|    2|           1|\n",
            "+-----+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Joins\n",
        "# Join employees and attendance → Get attendance % (Present days / Total days).\n",
        "# Join employees and bonuses → Show top 3 employees by TotalCompensation.\n",
        "# Multi-level join: employees + bonuses + attendance .\n",
        "\n",
        "from pyspark.sql.functions import count, sum\n",
        "\n",
        "attendance_grouped = attendancedf.groupBy(\"EmpID\").pivot(\"Status\").count().fillna(0)\n",
        "attendance_grouped = attendance_grouped.withColumn(\"AttendancePercent\",round(col(\"Present\") / (col(\"Present\") + col(\"Absent\")) * 100, 2))\n",
        "\n",
        "employeesdf.join(attendance_grouped, \"EmpID\", \"left\").select(\"EmpID\", \"Name\", \"AttendancePercent\").show()\n",
        "\n",
        "emp_with_bonus.orderBy(col(\"TotalCompensation\").desc()).select(\"EmpID\", \"Name\", \"TotalCompensation\").show(3)\n",
        "\n",
        "joined_df = employeesdf.join(bonusesdf, \"EmpID\").join(attendance_grouped, \"EmpID\")\n",
        "joined_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s337PKgIVwW4",
        "outputId": "6b3ad71f-c033-4dca-e6de-d14888cc42a3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+-----------------+\n",
            "|EmpID|  Name|AttendancePercent|\n",
            "+-----+------+-----------------+\n",
            "|    1| Anita|            100.0|\n",
            "|    2|   Raj|             50.0|\n",
            "|    3|Simran|            100.0|\n",
            "|    4| Aamir|              0.0|\n",
            "|    5| Nisha|            100.0|\n",
            "+-----+------+-----------------+\n",
            "\n",
            "+-----+------+-----------------+\n",
            "|EmpID|  Name|TotalCompensation|\n",
            "+-----+------+-----------------+\n",
            "|    2|   Raj|            87000|\n",
            "|    3|Simran|            81500|\n",
            "|    4| Aamir|            66000|\n",
            "+-----+------+-----------------+\n",
            "only showing top 3 rows\n",
            "\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+------+-------+-----------------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|Bonus|Year|Absent|Present|AttendancePercent|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+------+-------+-----------------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|     NULL|       4.11| 5000|2023|     0|      2|            100.0|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|       5.24| 7000|2023|     1|      1|             50.0|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|       2.92| 6500|2023|     0|      2|            100.0|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|       5.56| 6000|2023|     2|      0|              0.0|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|       2.43| 4000|2023|     0|      2|            100.0|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+------+-------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. String & Date Functions\n",
        "# Extract year and month from JoinDate .\n",
        "# Mask employee names using regex.\n",
        "# Use substring() to create EmpCode like \"EMP001\".\n",
        "\n",
        "from pyspark.sql.functions import year, month, regexp_replace, lpad, concat, lit\n",
        "\n",
        "employeesdf = employeesdf.withColumn(\"JoinYear\", year(\"JoinDate\")) \\\n",
        "                     .withColumn(\"JoinMonth\", month(\"JoinDate\"))\n",
        "\n",
        "\n",
        "employeesdf = employeesdf.withColumn(\"MaskedName\", regexp_replace(\"Name\", r\"(?<=.).(?=.)\", \"*\"))\n",
        "\n",
        "\n",
        "employeesdf = employeesdf.withColumn(\"EmpCode\", concat(lit(\"EMP\"), lpad(col(\"EmpID\").cast(\"string\"), 3, \"0\")))\n",
        "\n",
        "employeesdf.select(\"EmpID\", \"Name\", \"MaskedName\", \"EmpCode\", \"JoinYear\", \"JoinMonth\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mn84kiHHVwQA",
        "outputId": "8383ea76-8617-4ea0-ff7b-2aae72cb9264"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+----------+-------+--------+---------+\n",
            "|EmpID|  Name|MaskedName|EmpCode|JoinYear|JoinMonth|\n",
            "+-----+------+----------+-------+--------+---------+\n",
            "|    1| Anita|     A***a| EMP001|    2021|        5|\n",
            "|    2|   Raj|       R*j| EMP002|    2020|        3|\n",
            "|    3|Simran|    S****n| EMP003|    2022|        7|\n",
            "|    4| Aamir|     A***r| EMP004|    2019|       11|\n",
            "|    5| Nisha|     N***a| EMP005|    2023|        1|\n",
            "+-----+------+----------+-------+--------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Conditional & Null Handling\n",
        "# Use when/otherwise to label performance:\n",
        "# “High” if Bonus > 6000\n",
        "# “Medium” if 4000–6000\n",
        "# “Low” otherwise\n",
        "# Handle missing ManagerID using fillna(\"No Manager\") .\n",
        "from pyspark.sql.functions import when\n",
        "\n",
        "emp_with_bonus = emp_with_bonus.withColumn(\"Performance\",when(col(\"Bonus\") > 6000, \"High\").when((col(\"Bonus\") >= 4000) & (col(\"Bonus\") <= 6000), \"Medium\").otherwise(\"Low\"))\n",
        "\n",
        "employees_filled = employeesdf.fillna({\"ManagerID\": \"No Manager\"})\n",
        "\n",
        "emp_with_bonus.select(\"EmpID\", \"Name\", \"Bonus\", \"Performance\").show()\n",
        "employees_filled.select(\"EmpID\", \"Name\", \"ManagerID\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTqpMw4RVwJZ",
        "outputId": "28e4733f-4680-4b51-e82d-4ccdcc16642e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+-----+-----------+\n",
            "|EmpID|  Name|Bonus|Performance|\n",
            "+-----+------+-----+-----------+\n",
            "|    1| Anita| 5000|     Medium|\n",
            "|    2|   Raj| 7000|       High|\n",
            "|    3|Simran| 6500|       High|\n",
            "|    4| Aamir| 6000|     Medium|\n",
            "|    5| Nisha| 4000|     Medium|\n",
            "+-----+------+-----+-----------+\n",
            "\n",
            "+-----+------+---------+\n",
            "|EmpID|  Name|ManagerID|\n",
            "+-----+------+---------+\n",
            "|    1| Anita|     NULL|\n",
            "|    2|   Raj|        1|\n",
            "|    3|Simran|        1|\n",
            "|    4| Aamir|        1|\n",
            "|    5| Nisha|        1|\n",
            "+-----+------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Spark SQL\n",
        "# Create and use database hr .\n",
        "# Save all DataFrames as tables: employees , attendance , bonuses .\n",
        "# Write SQL queries:\n",
        "# Top paid employee in each department.\n",
        "# Attendance rate by department.\n",
        "# Employees joined after 2021 with salary > 70,000.\n",
        "\n",
        "employeesdf.createOrReplaceTempView(\"employees\")\n",
        "attendancedf.createOrReplaceTempView(\"attendance\")\n",
        "bonusesdf.createOrReplaceTempView(\"bonuses\")\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "    SELECT Department, Name, Salary\n",
        "    FROM (\n",
        "        SELECT *, ROW_NUMBER() OVER(PARTITION BY Department ORDER BY Salary DESC) AS rn\n",
        "        FROM employees\n",
        "    ) WHERE rn = 1\n",
        "\"\"\").show()\n",
        "\n",
        "attendancedf.createOrReplaceTempView(\"attendance\")\n",
        "spark.sql(\"\"\"\n",
        "    SELECT e.Department,\n",
        "           ROUND(SUM(CASE WHEN a.Status = 'Present' THEN 1 ELSE 0 END) * 100.0 / COUNT(*), 2) AS AttendanceRate\n",
        "    FROM employees e\n",
        "    JOIN attendance a ON e.EmpID = a.EmpID\n",
        "    GROUP BY e.Department\n",
        "\"\"\").show()\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "    SELECT *\n",
        "    FROM employees\n",
        "    WHERE JoinDate > '2021-12-31' AND Salary > 70000\n",
        "\"\"\").show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35KfaI80VwB4",
        "outputId": "45790d25-0a17-4576-f31c-03fc5f642beb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----+------+\n",
            "| Department| Name|Salary|\n",
            "+-----------+-----+------+\n",
            "|Engineering|  Raj| 80000|\n",
            "|         HR|Anita| 55000|\n",
            "|  Marketing|Aamir| 60000|\n",
            "+-----------+-----+------+\n",
            "\n",
            "+-----------+--------------+\n",
            "| Department|AttendanceRate|\n",
            "+-----------+--------------+\n",
            "|Engineering|         75.00|\n",
            "|         HR|        100.00|\n",
            "|  Marketing|          0.00|\n",
            "+-----------+--------------+\n",
            "\n",
            "+-----+------+-----------+----------+------+---------+-----------+--------+---------+----------+-------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|JoinYear|JoinMonth|MaskedName|EmpCode|\n",
            "+-----+------+-----------+----------+------+---------+-----------+--------+---------+----------+-------+\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|       2.92|    2022|        7|    S****n| EMP003|\n",
            "+-----+------+-----------+----------+------+---------+-----------+--------+---------+----------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Advanced (Optional)\n",
        "# Use a UDF to classify department as \"Tech\" vs \"Non-Tech\".\n",
        "# Create a view emp_attendance_summary .\n",
        "# Save it as Parquet partitioned by Department .\n",
        "\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "def classify_department(dept):\n",
        "    return \"Tech\" if dept in [\"Engineering\"] else \"Non-Tech\"\n",
        "\n",
        "dept_udf = udf(classify_department, StringType())\n",
        "employeesdf = employeesdf.withColumn(\"DeptType\", dept_udf(\"Department\"))\n",
        "\n",
        "emp_attendance_summary = joined_df.select(\"EmpID\", \"Name\", \"Department\", \"Present\", \"Absent\", \"AttendancePercent\")\n",
        "emp_attendance_summary.createOrReplaceTempView(\"emp_attendance_summary\")\n",
        "\n",
        "emp_attendance_summary.write.mode(\"overwrite\").partitionBy(\"Department\").parquet(\"/tmp/emp_attendance_summary\")\n",
        "emp_attendance_summary.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhGcSVGkVvz5",
        "outputId": "a6f320b3-6f41-4bec-bea7-2feebf5496b1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+-----------+-------+------+-----------------+\n",
            "|EmpID|  Name| Department|Present|Absent|AttendancePercent|\n",
            "+-----+------+-----------+-------+------+-----------------+\n",
            "|    1| Anita|         HR|      2|     0|            100.0|\n",
            "|    2|   Raj|Engineering|      1|     1|             50.0|\n",
            "|    3|Simran|Engineering|      2|     0|            100.0|\n",
            "|    4| Aamir|  Marketing|      0|     2|              0.0|\n",
            "|    5| Nisha|         HR|      2|     0|            100.0|\n",
            "+-----+------+-----------+-------+------+-----------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}