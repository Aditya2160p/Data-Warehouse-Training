{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5kemfBFd1DJ",
        "outputId": "caceff4d-6007-4077-8f31-bacc34e4e63d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+-----------+-----+--------+----------+\n",
            "|ProductID|ProductName|   Category|Price|Quantity|  SaleDate|\n",
            "+---------+-----------+-----------+-----+--------+----------+\n",
            "|        1|     Laptop|Electronics|900.0|       2|2025-05-01|\n",
            "|        2|      Phone|Electronics|700.0|       1|2025-05-02|\n",
            "|        3|         TV|Electronics|500.0|       4|2025-05-03|\n",
            "|        4|       Book|      Books| 80.0|      10|2025-05-04|\n",
            "|        5|      Shoes|    Fashion|500.0|       3|2025-05-05|\n",
            "+---------+-----------+-----------+-----+--------+----------+\n",
            "\n",
            "+---------+-----------+-----------+-----+--------+----------+\n",
            "|ProductID|ProductName|   Category|Price|Quantity|  SaleDate|\n",
            "+---------+-----------+-----------+-----+--------+----------+\n",
            "|        1|     Laptop|Electronics|900.0|       2|2025-05-01|\n",
            "|        2|      Phone|Electronics|700.0|       1|2025-05-02|\n",
            "|        3|         TV|Electronics|500.0|       4|2025-05-03|\n",
            "|        4|       Book|      Books| 80.0|      10|2025-05-04|\n",
            "|        5|      Shoes|    Fashion|500.0|       3|2025-05-05|\n",
            "+---------+-----------+-----------+-----+--------+----------+\n",
            "\n",
            "+---------+-----------+-----------+-----+--------+----------+\n",
            "|ProductID|ProductName|   Category|Price|Quantity|  SaleDate|\n",
            "+---------+-----------+-----------+-----+--------+----------+\n",
            "|        1|     Laptop|Electronics|900.0|       2|2025-05-01|\n",
            "|        2|      Phone|Electronics|700.0|       1|2025-05-02|\n",
            "+---------+-----------+-----------+-----+--------+----------+\n",
            "\n",
            "+-----------+-----+--------+---------+\n",
            "|ProductName|Price|Quantity|TotalSale|\n",
            "+-----------+-----+--------+---------+\n",
            "|     Laptop|900.0|       2|   1800.0|\n",
            "|      Phone|700.0|       1|    700.0|\n",
            "|         TV|500.0|       4|   2000.0|\n",
            "|       Book| 80.0|      10|    800.0|\n",
            "|      Shoes|500.0|       3|   1500.0|\n",
            "+-----------+-----+--------+---------+\n",
            "\n",
            "+-----------+---------+\n",
            "|   Category|TotalSold|\n",
            "+-----------+---------+\n",
            "|Electronics|        7|\n",
            "|    Fashion|        3|\n",
            "|      Books|       10|\n",
            "+-----------+---------+\n",
            "\n",
            "+-----------+---------+\n",
            "|ProductName|TotalSale|\n",
            "+-----------+---------+\n",
            "|         TV|   2000.0|\n",
            "|     Laptop|   1800.0|\n",
            "|      Shoes|   1500.0|\n",
            "|       Book|    800.0|\n",
            "|      Phone|    700.0|\n",
            "+-----------+---------+\n",
            "\n",
            "+---------+-----------+-----------+-----+--------+----------+\n",
            "|ProductID|ProductName|   Category|Price|Quantity|  SaleDate|\n",
            "+---------+-----------+-----------+-----+--------+----------+\n",
            "|      101|      Mouse|Electronics| 25.0|       2|2025-06-01|\n",
            "+---------+-----------+-----------+-----+--------+----------+\n",
            "\n",
            "+---------+-----------+-----------+-----+--------+----------+\n",
            "|ProductID|ProductName|   Category|Price|Quantity|  SaleDate|\n",
            "+---------+-----------+-----------+-----+--------+----------+\n",
            "|      101|      Mouse|Electronics| 25.0|       2|2025-06-01|\n",
            "|      102|        Pen| Stationery|  5.0|       1|2025-06-01|\n",
            "+---------+-----------+-----------+-----+--------+----------+\n",
            "\n",
            "+----------+------+------+----------+----------+\n",
            "|CustomerID|  Name|Gender|      City|SignupDate|\n",
            "+----------+------+------+----------+----------+\n",
            "|         3|   Raj|     M|   Chennai|2025-02-15|\n",
            "|         5|Muneeb|     M| Bangalore|2025-03-10|\n",
            "|         1|Aditya|     M|Coimbatore|2025-01-01|\n",
            "+----------+------+------+----------+----------+\n",
            "\n",
            "+---------+-----------+------+----------+\n",
            "|ProductID|ProductName|  Name|      City|\n",
            "+---------+-----------+------+----------+\n",
            "|        3|         TV|   Raj|   Chennai|\n",
            "|        5|      Shoes|Muneeb| Bangalore|\n",
            "|        1|     Laptop|Aditya|Coimbatore|\n",
            "+---------+-----------+------+----------+\n",
            "\n",
            "+------+--------+\n",
            "|  Name|Quantity|\n",
            "+------+--------+\n",
            "|   Raj|       4|\n",
            "|Muneeb|       3|\n",
            "+------+--------+\n",
            "\n",
            "+-----------+-----+--------+------+\n",
            "|ProductName|Price|Quantity| Total|\n",
            "+-----------+-----+--------+------+\n",
            "|     Laptop|900.0|       2|1800.0|\n",
            "|         TV|500.0|       4|2000.0|\n",
            "|      Shoes|500.0|       3|1500.0|\n",
            "+-----------+-----+--------+------+\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession, Row\n",
        "from datetime import date\n",
        "\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "\n",
        "# 1. Create a new database named sales_db .\n",
        "# 2. Set the current database to sales_db .\n",
        "# 3. Create a table product_sales with columns:\n",
        "# ProductID (INT)\n",
        "# ProductName (STRING)\n",
        "# Category (STRING)\n",
        "# Price (DOUBLE)\n",
        "# Quantity (INT)\n",
        "# SaleDate (DATE)\n",
        "# 4. Insert at least 5 rows into product_sales\n",
        "data = [\n",
        "    Row(ProductID=1, ProductName=\"Laptop\", Category=\"Electronics\", Price=900.0, Quantity=2, SaleDate=date(2025, 5, 1)),\n",
        "    Row(ProductID=2, ProductName=\"Phone\", Category=\"Electronics\", Price=700.0, Quantity=1, SaleDate=date(2025, 5, 2)),\n",
        "    Row(ProductID=3, ProductName=\"TV\", Category=\"Electronics\", Price=500.0, Quantity=4, SaleDate=date(2025, 5, 3)),\n",
        "    Row(ProductID=4, ProductName=\"Book\", Category=\"Books\", Price=80.0, Quantity=10, SaleDate=date(2025, 5, 4)),\n",
        "    Row(ProductID=5, ProductName=\"Shoes\", Category=\"Fashion\", Price=500.0, Quantity=3, SaleDate=date(2025, 5, 5)),\n",
        "]\n",
        "\n",
        "df_product_sales = spark.createDataFrame(data)\n",
        "\n",
        "df_product_sales.write.mode(\"overwrite\").parquet(\"parquet_data/product_sales\")\n",
        "\n",
        "df_sales_read = spark.read.parquet(\"parquet_data/product_sales\")\n",
        "df_sales_read.createOrReplaceTempView(\"product_sales\")\n",
        "df_sales_read.show()\n",
        "\n",
        "# 5. Select all records\n",
        "spark.sql(\"SELECT * FROM product_sales\").show()\n",
        "\n",
        "# 6. Products where price > 500\n",
        "spark.sql(\"SELECT * FROM product_sales WHERE Price > 500\").show()\n",
        "\n",
        "# 7. Total sale amount\n",
        "spark.sql(\"SELECT ProductName, Price, Quantity, (Price * Quantity) AS TotalSale FROM product_sales\").show()\n",
        "\n",
        "# 8. Number of products sold in each Category\n",
        "spark.sql(\"SELECT Category, SUM(Quantity) AS TotalSold FROM product_sales GROUP BY Category\").show()\n",
        "\n",
        "# 9. Sort products by total sales descending\n",
        "spark.sql(\"\"\"\n",
        "    SELECT ProductName, (Price * Quantity) AS TotalSale\n",
        "    FROM product_sales\n",
        "    ORDER BY TotalSale DESC\n",
        "\"\"\").show()\n",
        "\n",
        "# 10. Create a PySpark DataFrame with dummy product data\n",
        "data = [\n",
        "    (101, 'Mouse', 'Electronics', 25.0, 2, '2025-06-01'),\n",
        "    (102, 'Pen', 'Stationery', 5.0, 1, '2025-06-01')\n",
        "]\n",
        "columns = ['ProductID', 'ProductName', 'Category', 'Price', 'Quantity', 'SaleDate']\n",
        "temp_df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# 11. Register it as a temporary view\n",
        "temp_df.createOrReplaceTempView(\"temp_orders\")\n",
        "\n",
        "# 12. Query: quantity > 1\n",
        "spark.sql(\"SELECT * FROM temp_orders WHERE Quantity > 1\").show()\n",
        "\n",
        "# 13. Create a global temp view\n",
        "temp_df.createOrReplaceGlobalTempView(\"global_orders\")\n",
        "\n",
        "# 14. Query global view (in same or different session)\n",
        "spark.sql(\"SELECT * FROM global_temp.global_orders\").show()\n",
        "\n",
        "\n",
        "# 15. Create a second table customer_details with:\n",
        "# CustomerID , Name , Gender , City , SignupDate\n",
        "# 16. Insert at least 3 records into customer_details\n",
        "\n",
        "customer_data = [\n",
        "    Row(CustomerID=1, Name='Aditya', Gender='M', City='Coimbatore', SignupDate=date(2025, 1, 1)),\n",
        "    Row(CustomerID=3, Name='Raj', Gender='M', City='Chennai', SignupDate=date(2025, 2, 15)),\n",
        "    Row(CustomerID=5, Name='Muneeb', Gender='M', City='Bangalore', SignupDate=date(2025, 3, 10)),\n",
        "]\n",
        "\n",
        "df_customers = spark.createDataFrame(customer_data)\n",
        "\n",
        "df_customers.write.mode(\"overwrite\").parquet(\"parquet_data/customer_details\")\n",
        "\n",
        "df_customers_read = spark.read.parquet(\"parquet_data/customer_details\")\n",
        "df_customers_read.createOrReplaceTempView(\"customer_details\")\n",
        "\n",
        "\n",
        "spark.sql(\"SELECT * FROM customer_details\").show()\n",
        "\n",
        "\n",
        "# 17. Join on ProductID = CustomerID\n",
        "spark.sql(\"\"\"\n",
        "    SELECT p.ProductID, p.ProductName, c.Name, c.City\n",
        "    FROM product_sales p\n",
        "    JOIN customer_details c\n",
        "    ON p.ProductID = c.CustomerID\n",
        "\"\"\").show()\n",
        "\n",
        "# 18. Customers who bought more than 2 products\n",
        "spark.sql(\"\"\"\n",
        "    SELECT c.Name, p.Quantity\n",
        "    FROM product_sales p\n",
        "    JOIN customer_details c\n",
        "    ON p.ProductID = c.CustomerID\n",
        "    WHERE p.Quantity > 2\n",
        "\"\"\").show()\n",
        "\n",
        "# 19. Create view sales_summary\n",
        "spark.sql(\"\"\"\n",
        "    CREATE OR REPLACE TEMP VIEW sales_summary AS\n",
        "    SELECT ProductName, Price, Quantity, (Price * Quantity) AS Total\n",
        "    FROM product_sales\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "# 20. Query view where Total > 1000\n",
        "spark.sql(\"SELECT * FROM sales_summary WHERE Total > 1000\").show()\n",
        "\n",
        "# 21. Drop the view\n",
        "spark.sql(\"DROP VIEW IF EXISTS sales_summary\")\n",
        "\n",
        "# 22. Drop tables\n",
        "spark.sql(\"DROP TABLE IF EXISTS product_sales\")\n",
        "spark.sql(\"DROP TABLE IF EXISTS customer_details\")\n",
        "\n",
        "# 23. Drop the database\n",
        "spark.sql(\"DROP DATABASE IF EXISTS sales_db CASCADE\")\n"
      ]
    }
  ]
}